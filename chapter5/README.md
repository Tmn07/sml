## 第五章

- 决策树

### 信息增益

#### 熵
k为分类数
$$
熵：
H(D) = - \sum_{i=1}^k\frac{|C_i|}{|D|}log_2\frac{|C_i|}{|D|}---(1)
$$



$D_i$是在X特征下划分的第i个的数据集
$$
特征X对于数据集的熵：
H_x(D) = - \sum_{i=1}^k\frac{|D_i|}{|D|}log_2\frac{|D_i|}{|D|}---(2)
$$

熵越大不确定性越大

#### 条件熵
A特征有n个取值
$$
H(D|A) = \sum_{i=1}^{n}\frac{|D_i|}{|D|}H(D_i)---(3)
$$
$$
在D_i数据集下的熵：
H(D_i) = - \sum_{j=1}^k\frac{|C_j|}{|D_i|}log_2\frac{|C_j|}{|D_i|}---(4)
$$
k为分类数
#### 信息增益

$$
特征A对于数据集D的信息增益：
g(D,A) = H(D) - H(D|A)---(5)
$$
用信息增益划分数据集时，存在偏向于选择取值较多的特征

$$
g_R(D,A) = \frac{g(D,A)}{H_A(D)} = \frac{式5}{式2}---(6)
$$


不存在上述问题

### 决策树

#### 树生成
- ID3以**信息增益**选择特征的划分
- C4.5以**信息增益比**选择特征的划分
- 易过度拟合
- 递归

#### 连续特征
- 


#### 树减枝
- 计算代价函数（包括经验和结构）//经验就是数据的拟合度，结构就是模型的复杂度
- 比较删除叶节点后，代价函数变化，如果代价变小则删除
- 动态规划?